---
title: "Big Data Analytics"
subtitle: 'Lecture 7:<br>Visualization II | Data Storage, Databases Interaction with R'
author: "Prof. Dr. Ulrich Matter"
date: "16/04/2020"
output:
  ioslides_presentation:
    css: ../../style/ioslides.css
    template: ../../style/nologo_template.html
logo: ../img/logo.png
bibliography: ../references/bigdata.bib
---


```{r set-options, echo=FALSE, cache=FALSE, purl=FALSE}
options(width = 100)
library(knitr)
```


# Updates

## Status

 1. Introduction: Big Data, Data Economy. Walkowiak (2016): Chapter 1.
 2. Computation and Memory in Applied Econometrics.
 3. Computation and Memory in Applied Econometrics II.*
 4. Advanced R Programming. Wickham (2019): Chapters 2, 3, 17,23, 24.
 5. Import, Cleaning and Transformation of Big Data. Walkowiak (2016): Chapter 3: p. 74‑118.
 6. Aggregation and Visualization. Walkowiak (2016): Chapter 3: p. 118‑127; Wickham et al.(2015); Schwabish (2014).
 7. *Data Visualization Part II & Data Storage, Databases Interaction with R. Walkowiak (2016): Chapter 5.
 8. Cloud Computing: Introduction/Overview, Distributed Systems, Walkowiak (2016): Chapter 4.*
 9. Applied Econometrics with Spark; Machine Learning and GPUs.
 10. Q&A (7 May, 2020).
 11. Q&A, Feedback. (14 May, 2020; Hand-in voice-over-slides presentations)

# Recap Week 6

## Setting

- Data source: NYC Taxi & Limousine Commission (TLC)
- Data on all trip records including pick-up and drop-off times/locations.
     - (2009-2018)
     - Trip-level observations
     - Amount of fare paid
     - Amount of tip paid, etc.
- All raw data: over 200GB 
     - *Here: First 1 million observations (in January 2009)*

## Data aggregation: The 'split-apply-combine' strategy

- Background: Compute a statistic for specific groups (e.g. women vs men,  etc.)

1. Split the data into subsamples (e.g. one for women, one for men)
2. Compute the statistic for each of the subsamples.
3. Combine all results in one table.


## Tow approaches discussed

- Data aggregation with chunked data files (`ff`)
- High-speed in-memory data aggregation with `data.table`


<!-- ## Necessary condition for `data.table` -->

<!-- - Data still fit into RAM -->
<!-- - Possible with our subsample of 1 million rows (on most modern computers). -->
<!-- - Unlikely to work well with the full data set (200GB) -->


## Visualization: Grammar of Graphics/`ggplot2`

```{r ggplot, echo=FALSE, out.width = "80%", fig.align='center', purl=FALSE}
include_graphics("../img/taxiplot.png")
```




# Data Visualization Part II


```{r warning=FALSE, echo=FALSE, message=FALSE}

# SET UP----
# see 05_aggregtion_visualization.Rmd for details
# load packages
library(data.table)
library(ggplot2)

# import data into RAM (needs around 200MB)
taxi <- fread("../data/tlc_trips.csv",
              nrows = 1000000)



# first, we remove the empty vars V8 and V9
taxi$V8 <- NULL
taxi$V9 <- NULL


# set covariate names according to the data dictionary
# see https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf
# note instead of taxizonne ids, long/lat are provided

varnames <- c("vendor_id",
              "pickup_time",
              "dropoff_time",
              "passenger_count",
              "trip_distance",
              "start_long",
              "start_lat",
              "dest_long",
              "dest_lat",
              "payment_type",
              "fare_amount",
              "extra",
              "mta_tax",
              "tip_amount",
              "tolls_amount",
              "total_amount")
names(taxi) <- varnames

# clean the factor levels
taxi$payment_type <- tolower(taxi$payment_type)
taxi$payment_type <- factor(taxi$payment_type, levels = unique(taxi$payment_type))     




```


## Visualization of spatial data with `ggplot2`

- Data source: NYC Taxi & Limousine Commission (TLC).
- Data on all trip records including *pick-up and drop-off times/locations*.


## Preparations

- Load packages for GIS data/operations

```{r message=FALSE, warning=FALSE}
# load GIS packages
library(rgdal)
library(rgeos)
```

## Download map data

```{r message=FALSE, warning=FALSE}
# download the zipped shapefile to a temporary file, unzip
URL <- "https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nycd_19a.zip"
tmp_file <- tempfile()
download.file(URL, tmp_file)
file_path <- unzip(tmp_file, exdir= "../data")
# delete the temporary file
unlink(tmp_file)

```

## Import map data

```{r message=FALSE, warning=FALSE}
# read GIS data
nyc_map <- readOGR(file_path[1], verbose = FALSE)

# have a look at the polygons that constitute the map
summary(nyc_map)
```


## Change map projection

```{r}
# transform the projection
nyc_map <- spTransform(nyc_map, 
                       CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
# check result
summary(nyc_map)
```

## Prepare map for plotting with `ggplot2`

```{r warning=FALSE, message=FALSE}
nyc_map <- fortify(nyc_map)
```


## Prepare pick-up and drop-off data


```{r}
# taxi trips plot data
taxi_trips <- taxi[start_long <= max(nyc_map$long) & 
                        start_long >= min(nyc_map$long) &
                        dest_long <= max(nyc_map$long) &
                        dest_long >= min(nyc_map$long) &
                        start_lat <= max(nyc_map$lat) & 
                        start_lat >= min(nyc_map$lat) &
                        dest_lat <= max(nyc_map$lat) &
                        dest_lat >= min(nyc_map$lat) 
                        ]
taxi_trips <- taxi_trips[sample(nrow(taxi_trips), 50000)]

```


## Code time dimension(s)

```{r}
taxi_trips$start_time <- hour(taxi_trips$pickup_time)
```


```{r}
# define new variable for facets
taxi_trips$time_of_day <- "Morning"
taxi_trips[start_time > 12 & start_time < 17]$time_of_day <- "Afternoon"
taxi_trips[start_time %in% c(17:24, 0:5)]$time_of_day <- "Evening/Night"
taxi_trips$time_of_day  <- factor(taxi_trips$time_of_day, levels = c("Morning", "Afternoon", "Evening/Night"))

```


## Base plot: Map of NYC


```{r}
# set up the canvas
locations <- ggplot(taxi_trips, aes(x=long, y=lat))
# add the map geometry
locations <- locations + geom_map(data = nyc_map,
                                  map = nyc_map,
                                  aes(map_id = id))
locations
```

## Add pick-up locations

```{r}
# add pick-up locations to plot
locations + 
     geom_point(aes(x=start_long, y=start_lat),
                color="orange",
                size = 0.1,
                alpha = 0.2)

```

## Add drop-off locations

```{r}
# add pick-up locations to plot
locations +
     geom_point(aes(x=dest_long, y=dest_lat),
                color="steelblue",
                size = 0.1,
                alpha = 0.2) +
     geom_point(aes(x=start_long, y=start_lat),
                color="orange",
                size = 0.1,
                alpha = 0.2)
 

```


## Taxi traffic over the course of a day

```{r fig.height=3, fig.width=9}

# pick-up locations 
locations +
     geom_point(aes(x=start_long, y=start_lat),
                color="orange",
                size = 0.1,
                alpha = 0.2) +
     facet_wrap(vars(time_of_day))
 
```

## Taxi traffic over the course of a day

```{r fig.height=3, fig.width=9}

# drop-off locations 
locations +
     geom_point(aes(x=dest_long, y=dest_lat),
                color="steelblue",
                size = 0.1,
                alpha = 0.2) +
     facet_wrap(vars(time_of_day))
 
```


## Taxi traffic over the course of a day

```{r}
# drop-off locations 
locations +
     geom_point(aes(x=dest_long, y=dest_lat, color = start_time ),
                size = 0.1,
                alpha = 0.2) +
     scale_colour_gradient2( low = "red", mid = "yellow", high = "red",
                             midpoint = 12)
 
```





# Data Storage and Databases


## (Big) Data Storage

 - $(I)$ How can we store large data sets permanently on a mass storage device in an efficient way (here, efficient can be understood as 'not taking up too much space')?
 - $(II)$ How can we load (parts of) this data set in an efficient way (here, efficient~fast) for analysis?

## We look at this problem in two situations: 

 - The data need to be stored locally (e.g., on the hard disk of our laptop).
 - The data can be stored on a server 'in the cloud' (next lecture).

## Many new database types for Big Data

```{r whatis, echo=FALSE, out.width = "80%", fig.align='center', purl=FALSE, fig.cap="NoSQL/NewSQL systems. Source: https://img.deusm.com/informationweek/2014/06/1269559/NoSQL-&-NewSQL.jpg"}
include_graphics("https://img.deusm.com/informationweek/2014/06/1269559/NoSQL-&-NewSQL.jpg")
```




## Simple distinction

- *SQL/Relational Database Systems (RDBMS)*: Relational data model, tabular relations.
     - In use for a long time, very mature, very accurate/stable.
- *NoSQL ('non-SQL', sometimes 'Not only SQL')*: Different data models, column, document, key-value, graph.
     - Horizontal scaling.
     - Non-tabular data.
     - Typically used to handle very large amounts of data.


## RDBMS basics

- *Relational data model*
     - Data split into several tables (avoid redundancies).
     - Tables are linked via key-variables/columns.
     - Save storage space.
- *Indexing*
     - Table columns (particularly keys) are indexed.
     - Reduces number of disk accesses required to query data.
     - Makes querying/loading of data more efficient/faster.




## Getting started with (R)SQLite

- [SQLite](https://sqlite.org/index.html)
     - Free, full-featured SQL database engine.
     - Widely used across platforms.
     - Typically pre-installed on Windows/MacOSX.
- [RSQLite](https://cran.r-project.org/web/packages/RSQLite/index.html)
     - Embeds SQLite in R.
     - Use SQLite from within an R session.


## Exercise 1:  First steps in SQLite (Terminal)

- Set up a new database called `mydb.sqlite`.

```{bash eval=FALSE}
cd materials/data 
```

```{bash eval= FALSE}
sqlite3 mydb.sqlite
```

```{sql eval = FALSE}
.tables
```


## Import data from CSV files

```{r echo=FALSE, message=FALSE}
library(DBI)
con <- dbConnect(RSQLite::SQLite(), "../data/mydb.sqlite")
```


```{sql connection=con, eval = FALSE}
CREATE TABLE econ(
"date" DATE,
"pce" REAL,
"pop" INTEGER,
"psavert" REAL,
"uempmed" REAL,
"unemploy" INTEGER
);

.mode csv
.import economics.csv econ
```


## Inspect the database


```{}
.tables
```

```{}
# econ
```

```{}
.schema econ
```

```{}
# CREATE TABLE econ(
# "date" DATE,
# "pce" REAL,
# "pop" INTEGER,
# "psavert" REAL,
# "uempmed" REAL,
# "unemploy" INTEGER
# );
```

## Set options for output

```{sql connection=con, eval = FALSE}
.header on
```

```{sql connection=con, eval = FALSE}
.mode columns
```



## Issue queries: Example 1

In our first query, we select all (`*`) variable values of the observation of January 1968.

```{sql connection=con}
select * from econ where date = '1968-01-01'
```

## Issue queries: Example 2

Now let's select all year/months in which there were more than 15 million unemployed, ordered by date.

```{sql connection=con}
select date from econ 
where unemploy > 15000
order by date;
```

## Close SQLite

When done working with the database, we can exit SQLite with the `.quit` command.




## Exercise 2: Indices and joins

 - Import several related tables.
 - Add indices to tables. 

## Initiate DB, import data

We set up a new database called `air.sqlite` and import the csv-file `flights.csv` (used in previous lectures) as a first table.

```{bash echo=TRUE, eval=FALSE}
# create database and run sqlite
sqlite3 air.sqlite

```

## Import data from CSVs


```{sql connection=con, eval = FALSE}
.mode csv
.import flights.csv flights
```


```{r echo=FALSE, message=FALSE}
library(DBI)
# set up a connection for the examples
con_air <- dbConnect(RSQLite::SQLite(), "../data/air_final.sqlite")
```


## Inspect the `flights` table

Again, we can check if everything worked out well with `.tables` and `.schema`.


```{sql connection=con_air, eval = FALSE}
.tables
.schema flights
```

## Related tables 

- [`airports.csv`](http://stat-computing.org/dataexpo/2009/airports.csv): Describes the locations of US Airports (relates to `origin` and `dest`).
- [`carriers.csv`](http://stat-computing.org/dataexpo/2009/carriers.csv): A listing of carrier codes with full names (relates to the `carrier`-column in `flights`.


```{r echo=FALSE, eval=FALSE}
# ASA source
URL_AIRPORTS <- "http://stat-computing.org/dataexpo/2009/airports.csv"
URL_CARRIERS <- "http://stat-computing.org/dataexpo/2009/carriers.csv"

# download
download.file(URL_AIRPORTS, destfile = "../data/airports.csv", quiet = TRUE)
download.file(URL_CARRIERS, destfile = "../data/carriers.csv", quiet = TRUE)

# re-format (facilitates import)
fwrite(fread("../data/airports.csv"), "../data/airports.csv")
fwrite(fread("../data/carriers.csv"), "../data/carriers.csv")

```


## Import related tables

Import from csv-file
```{sql connection=con_air, eval = FALSE}
.mode csv
.import airports.csv airports
.import carriers.csv carriers
```

Inspect the result
```{sql connection=con_air, eval = FALSE}
.tables
.schema airports
.schema carriers
```

## Issue queries with joins

 - Goal: A table containing flights data for all `United Air Lines Inc.`-flights departing from `Newark Intl` airport, ordered by flight number. 
 - For the sake of the exercise, we only show the first 10 results of this query (`LIMIT 10`).


## Issue queries with joins

```{sql connection=con_air, eval = TRUE}
SELECT 
year,
month, 
day,
dep_delay,
flight
FROM (flights INNER JOIN airports ON flights.origin=airports.iata) 
INNER JOIN carriers ON flights.carrier = carriers.Code
WHERE carriers.Description = 'United Air Lines Inc.'
AND airports.airport = 'Newark Intl'
ORDER BY flight
LIMIT 10;

```

## Add indices

```{sql connection=con_air, eval = FALSE}
CREATE INDEX iata_airports ON airports (iata);
CREATE INDEX origin_flights ON flights (origin);
CREATE INDEX carrier_flights ON flights (carrier);
CREATE INDEX code_carriers ON carriers (code);

```


## Re-run the query (with indices)

```{sql connection=con_air, eval = TRUE}
SELECT 
year,
month, 
day,
dep_delay,
flight
FROM (flights INNER JOIN airports ON flights.origin=airports.iata) 
INNER JOIN carriers ON flights.carrier = carriers.Code
WHERE carriers.Description = 'United Air Lines Inc.'
AND airports.airport = 'Newark Intl'
ORDER BY flight
LIMIT 10;

```



## SQLite from within R

- Use `RSQLite` to set up and query `air.sqlite` as shown above.
- All done from within an R session.


## Creating a new database with `RSQLite`

```{r}
# load packages
library(RSQLite)

# initiate the database
con_air <- dbConnect(SQLite(), "../data/air.sqlite")
```

## Importing data


```{r}

# import data into current R sesssion
flights <- fread("../data/flights.csv")
airports <- fread("../data/airports.csv")
carriers <- fread("../data/carriers.csv")

# add tables to database
dbWriteTable(con_air, "flights", flights)
dbWriteTable(con_air, "airports", airports)
dbWriteTable(con_air, "carriers", carriers)

```

## Issue queries with `RSQLite`

```{r}
# define query
delay_query <-
"SELECT 
year,
month, 
day,
dep_delay,
flight
FROM (flights INNER JOIN airports ON flights.origin=airports.iata) 
INNER JOIN carriers ON flights.carrier = carriers.Code
WHERE carriers.Description = 'United Air Lines Inc.'
AND airports.airport = 'Newark Intl'
ORDER BY flight
LIMIT 10;
"
```

## Issue queries with `RSQLite`

```{r}
# issue query
delays_df <- dbGetQuery(con_air, delay_query)
delays_df
```

## Close the connection to SQLite

```{r}
dbDisconnect(con_air)
```





```{r echo=FALSE}
# clean up
unlink("../data/air.sqlite")
```



## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>


